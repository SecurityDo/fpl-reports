* geoip(ip_address)
** return an object with all the fields.
** return an empty object if the address is not internet IP address
----
let info = geoip("8.8.8.8")
// OR
let {city, country, isp} = geoip("8.8.8.8")

{
  "city": "Mountain View",
  "country": "United States",
  "countryCode": "US",
  "isp": "Google LLC",
  "latitude": 37.4223,
  "longitude": -122.085,
  "org": "Level 3" 
}
----
* decoder_CSV(csvText)
** decode CSV format
----
let text = "2023-09-25 14:53:35","field1", "field2"
let fields = decoder_CSV(text)
// ["2023-09-25 14:53:35", "field1", "field2"]
----
* decoder_CEF(cefText) 
** decode CEF format
** return a object of the following fields:
** SignatureID
** Name
** Severity
** Vendor
** Product
** Version
** Fields 
----
let cef = `CEF:0|Imperva Inc|Attack Analytics|0|1|SQL Injection attack by several IPs using an unknown bot |MINOR|msg=On host "www.google.com" start=1646830802431 end=1646831309201 cs4=CloudWAF cs4Label=ImpervaAAPlatform`
let m = decoder_cef(cef)
///
{
  "Fields": {
    "msg": "On host \"www.google.com\""
    "ImpervaAAPlatform": "CloudWAF",
    "start": "1646830802431"
  },
  "Name": "SQL Injection attack by several IPs using an unknown bot ",
  "Product": "Attack Analytics",
  "Severity": "MINOR",
  "SignatureID": "1",
  "Vendor": "Imperva Inc",
  "Version": "0"
}
// CEF:2 format
let cef2 = `CEF:2|SentinelOne|Mgmt|ip=127.0.0.1|eventID=5126|eventDesc=SentinelOne: Device Control connected USB|eventSeverity=1|...`
----
* decoder_QuotedKeyValue(text) 
** decode quoted key value format k1="v1" k2="v2" ... 
* decoder_MixedKeyValue(text)
** decode key value pair where some value are quoted  k1=v1 k2="v2 v3"
* Fluency_EntityinfoCheck(entity, key)
** check if one key exists in one entity table
----
let hit = Fluency_EntityinfoCheck("HOME_NET", "20.0.0.1")
if hit {
  printf("home net")
} else {
  printf("internet")
}
----
* Fluency_EntityinfoLookup(entity, keyCol, key, valueCol)
** check value from one column based on key column value
** return an object {exist, value}
----
 let categoryID = "%%12547"
   let {exist, value} = fluencyEntityinfoLookup("AD_EventID_4719_CategoryId", "Id", categoryID, "Description")
   if exist {
      printf("value %s", value)
   }
----
* Fluency_LavadbFpl(searchText)
** Search LavaDB in FPL1.0
----
let office_aad_by_ops_fpl = `
    search {from="{{.from}}", to="{{.to}}"} sContent("@sender","office365") and sContent("@source","Audit.AzureActiveDirectory")
    let { {{ .groupBy }}  } = f("@fields")
    aggregate events = count() by {{ .groupBy }}
    sort 15 events
`

let office_aad_by_ops = fluencyLavadbFpl(
     template(office_aad_by_ops_fpl, 
              {from:"-24h", to:"@h", groupBy: "Operation"}))

return {office_aad_by_ops}
----

* Fluency_BehaviorSearch(query, from, to, ()=>{})
** Search Fluency Behavior Event database
* Fluency_SummarySearch(query, from, to, ()=>{})
** Search Fluency Behavior Summary database
----
function main() {
    let behaviorEvents = Fluency_BehaviorSearch("riskScore: [100 TO *]", "-10d@m", "@m", (obj) => {
       let {behaviorRule, behavior, riskScore, key } = obj
       return {behaviorRule, behavior, riskScore, key} 
    })
    let behaviorSummary = Fluency_SummarySearch("riskScore: [3000 TO *] AND NOT (status:new)", "-10d@m", "@m", (obj) => {
       let {id, behaviorRules, riskScore, key, dayIndex, status } = obj
       return {id, obj, behaviorRules, riskScore, key, dayIndex, status} 
    })
    
    return {behaviorEvents, behaviorSummary}
}
----
* Fluency_ResourceLoad(vendor, resource, customer, (obj <,customer>)=> {})
** vendor: Office365: resource: user, group, device, application, installedApp
** vendor Sentinelone: resource: agent, threat, application
** vendor AD: resource: user, asset
** vendor fehx (FireEyeHx):  resource: device
** vendor Qualys:  resource: host  
----
function main() {
  let users = Fluency_ResourceLoad("office365", "user", "*", (obj, customer) => {
      let fields = obj["@office365User"]
      let {userType, userPrincipalName, roles, accountEnabled, createdDateTime} = fields
      return {customer, userType, userPrincipalName, roles, accountEnabled, createdDateTime}
  })
  return {users}
}
----

* Fluency_Device_Lookup(ipAddress)
** Lookup device information from Fluency Device database
* Fluency_Device_Add(device)
** Add device information to Fluency Device database
* Fluency_Device_Update(ipAddress, newName)
** assign ipAddress to a new name
----
function main({obj, size}) {
   
   let sender = obj["@sender"]  
   let deviceEntry = Fluency_Device_Lookup(sender)
   
   if deviceEntry {
     printf("%s", deviceEntry)
   } else {
     printf("device not found")
     deviceEntry = {
       name:"$name",
       description:"Added by FPL processor",
       ips: [sender],
       group:"$group",
       device: {
         name:"$subCategory",
         category:"$category"
       }
     }
     Fluency_Device_Add(deviceEntry)
   }
   // call platform metric api...

   return "pass"
}
----
* Fluency_FusionEvent(partition, source)
** Send Fusion Event to Fluency Fusion Service (legacy)
----
   let t = new Time()
   let partition={
      partition: "default",
      dataType: "event",
      time_ms: t.UnixMilli()
   }
   let source={
     logon: { 
      ip:"10.132.47.10",
      domain:"TERPLAB.COM",
      username:"foobar"
     },
     dtype:"windows-logon"
   } 
   Fluency_FusionEvent(partition, source)   

----


== Platform API

* Platform_Metric_Counter(name, labels, increment)
** Write Counter metric to Prometheus database
----
let customer = obj["@customer"]
let dimensions = {
   namespace:"fluency",
   app:"import",
   eventType:"Office365",
   customer: customer
}
Platform_Metric_Counter("fluency_import_count", dimensions,1)
Platform_Metric_Counter("fluency_import_bytes", dimensions,size)
----
* Platform_Metric_QueryBuild(options)
** build a promQL query
** options: {metric, select, duration, stat, groupBy, aggregate, sort, limit}
* Platform_Metric_Query(query, time)
** return a fpl table
* Platform_Metric_QueryRange(query, from, to, step)
** return a fpl stream
----
function main() {
  // let query = `sum by(component) (increase(platform_component_bytes[5m]))`
  
  let query = Platform_Metric_QueryBuild({
    metric: "platform_component_bytes",
    duration: "1h",
    stat: "increase",
    aggregate:"sum",
    groupBy: "component",
    sort: "topk",
    limit: 3
  })
  let table = Platform_Metric_Query(query, "@h")
  
  // let keys = []
  let keys = table.Map((row) => {
     return row.component
  })
  
  let select = sprintf(`component=~"%s"`, keys.Join("|"))
  
  printf("%s",select)

  
  let query2 = Platform_Metric_QueryBuild({
    metric: "platform_component_bytes",
    select: select,
    duration: "1h",
    stat: "increase",
    aggregate:"sum",
    groupBy: "component"
  })
  
  let stream = Platform_Metric_QueryRange(query2, "-24h@h", "@h", "1h")
  //return {table}
  //let query = `sum by(eventType) (increase(fluency_import_bytes[1h]))`
  //let table = Platform_Metric_Query(query, "@h")
  //let stream = Platform_Metric_QueryRange(query, "-48h@h", "@h", "1h")
  return {table, stream}
}
----
* Platform_Metric_Sort({metric, select, groupBy, from, to, sort, limit})
** return top/bottom N rows
** metric:  metric name (must be a counter type)
** select:  metric label select
** groupBy: groupBy field(s), string or list of strings
** from/to:  time range in relative or absolute time format
** sort:  "topk" or "bottomk"
** limit:  number of rows
* Platform_Metric_Sort_Histogram({metric, select, groupBy, from, to, interval, sort, limit})
** return top/bottom N metrics
** metric:  metric name (must be a counter type)
** select:  metric label select
** groupBy: groupBy field(s), string or list of strings
** from/to:  time range in relative or absolute time format
** sort:  "topk" or "bottomk"
** limit:  number of rows
** interval:  histogram interval "1h", "1d", "1w", "1m"
----
function main({from="-24h@h", to="@h"}) {
  let groupBy="importSource"
  let options = {
    metric: "fluency_import_bytes",
    from: from,
    to: to,
    groupBy: groupBy,
    sort: "topk",
    limit: 10
  }
  // promQL: topk(10, sum by (importSource) (increase(fluency_import_bytes[24h])))
  let table = Platform_Metric_Sort(options)

  options.interval= "1h"
  // promQL: (sum by (importSource) (increase(fluency_import_bytes{importSource="foo" or importSource="bar"}[1h]))) [24h:1h]
  let histogram = Platform_Metric_Sort_Histogram(options)

  return {table, histogram}
}
----
* Platform_Metric_Alert_Counter_Stop(options)
** alert if counter stop increasing for some time
** options: {metric, select, groupBy, window, refWindow, interval, recordWindow}
** metric:  metric name (must be a counter type)
** select:  metric label select
** groupBy: groupBy field(s), string or list of strings
** duration: detection thresold. default is "10m"
** lookback: lookback offset. default is "1h"
** interval: polling interval. default is "1m"
** history: alert record duration, default is "1h"
** if no alert found, return undefined. 
** else return alerts.
----

  let options = {
    metric: `platform_component_total`,
    groupBy: "id",
    duration: "10m",
    lookback: "1h",
    interval: "1m",
    history: "1h"
  }
  let alerts = Platform_Metric_Alert_Counter_Stop(options)
  if alerts {
      alerts.Emit("Component_Stop", "component stopped for 10 minutes", "warn", 3600)
  }
----

