== Data Types

* Primitive Value
** string 
** int64
** float64
** bool
** null
** list of primitive value // []*primitive_value
*** 0-indexed
** map of primitive value  // map[string]*primitive_value
** list of interface       // Json Array []interface{}
** map of interface        // Json Object map[string]interface{}
** undefined

== Object Types

* Lambda
** simple expression: (x, y) => x+y
** block statements: 
** the parament support object/array destructuring: (obj) => obj.field1 + obj.field2   OR ({field1, field2}) 
---- 
  (x, y) => {
      let a = x + 1
      return a + y 
   }  // explicit return is required
----  
** the lambda parameter support object/array destructuring:
----
  // obj is a map/object type variable
  (obj) => obj.field1 + obj.field2   
  // OR
  ({field1, field2}) => field1 + field2
---- 
* FplTable
** Columns
** Rows

* FplMetric 
** from,to
** interval
** dimensions
** Metrics

* FplAlert

* Tuple:  list of Data Types or Object Types

* Map:   map of Data Types or Object Types

== Control Blocks

* if/elseif/else support
** value to bool conversion: false, null, undefined, 0, "", are false, all other values are true
----
let s = 100
if !s {
  printf("s has a false value")
} elseif s > 100 {
  printf("s is greater than 100")
} else {
  printf("s is less than or greater to 100")
}
----

* for loop support
** for <index> <entry> = range <list> { }
** for <key> <value> = range <map> { }
----
let lst = [0, 10, 20]
for i, v = range lst {
  printf("index: %d:  value: %d", i, v)
}

let map = {x:0, y:10, z:20}
for k, v = range map {
  printf("key: %s:  value: %d", k, v)
}
----

* break 
** break out of the current for loop

* continue
** skip the current iteration of the for loop

* return <value>

* single-line comments //

* multi-line comments  /*  */

== Function 

* function <name> (parameters) { }

* function main() {}
** main function is the execution starting point

== Utility Library (both input and output are primitive values)

* toLower(string) => string
** returns the string in lowercase
----
toLower("HELLO") // return the string "hello"
toLower(" World") // return the string " world"
----

* toUpper(string) => string
** returns the string in uppercase
----
toUpper("hello") // return the string "HELLO"
toUpper("wORld") // return the string "WORLD"
----

* startsWith(string, prefix) => bool
** returns true if string starts with prefix, false otherwise
** is case and whitespace sensitive
----
let s = "hello"
startsWith("hello", "he") // return true
startsWith("hello", "He") // return false
----

* endsWith(string, suffix) => bool
** returns true if string ends with suffix, false otherwise
** is case and whitespace sensitive
----
let s = "hello"
endsWith("hello", "llo") // return true
endsWith("hello", "LLO") // return false
----

* contains(string, subString) => bool
** returns true if subString exists in string false otherwise
** is case and whitespace sensitive
----
let s = "hello"
contains("hello", "ello") // return true
contains("hello", "hi") // return false
contains("hello", "He") // return false
----

* content(string1, string2) => bool
** returns true if string1 equals string2 false otherwise
** is case and whitespace sensitive
----
let s = "hello"
content(s, "hello") // return true
content(s, "Hello") // return false
content(s, "hello ") // return false
----

* trim(s, cutset) => string
** returns a sliced of the string s with all leading and trailing Unicode code points contained in cutset removed.
** cutset will be seen as a collection of characters
----
let s = "Hello and Hello"
trim(s, "Hello") // return the string "and"
trim(s, "o leH") // return the string "and"
trim(s, "Hel") // return the string "lo and Hello"
----

* trimPrefix(s, prefix) => string
** returns s without the provided leading prefix string. If s doesn't start with prefix, s is returned unchanged.
** is case and whitespace sensitive
----
let s = "Hello World"
trimPrefix(s, "Hello ") // return the string "World"
trimPrefix(s, "hello") // return the string "Hello World"
----

* trimSuffix(s, suffix) => string
** returns s without the provided trailing suffix string. If s doesn't end with suffix, s is returned unchanged.
** is case and whitespace sensitive
----
let s = "Hello World"
trimSuffix(s, "World") // return the string "Hello "
trimSuffix(s, "Hello") // return the string "Hello World"
----

* split(variable, delim)
** split the input string on delim and returns a list of string
----
let s = "1,2,3"
split(s, ",") // return a list ["1", "2", "3"]
split(s, "2") // return a list ["1,", ",3"]
split(s, "1") // return a list ["", ",2,3"]
----

* parseInt(s, base)
** parse a string in the given base into a 64bit integer
** if base is not given, it will default to 0
** if the base argument is 0, the true base is implied by the string's prefix (if present): 2 for "0b", 8 for "0" or "0o", 16 for "0x", and 10 otherwise
----
let s = 10
parseInt(s) // return the int64 value of 10
parseInt(s, 2) // return the int64 value of 2

let s = "0b10"
parseInt(s) // return the int64 value of 2
----

* parseFloat(s)
** parse a string into a 64bit floating-point number
----
parseFloat("10") // return the float64 value of 10.0
parseFloat("10.11") // return the float64 value of 10.11
----

* parseBool(s)
** returns the boolean value represented by the string. 
** it accepts 1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False. Any other values returns undefined
----
parseBool("1") // return the bool value true
parseBool("f") // return the bool value false
parseBoll("fa") // return undefined
----

* coalesce(var1, var2, var3, ...)
** return the first argument that is a non-empty string value, undefined otherwise
----
coalesce("str1", "str2", "str3", ...) // return the string "str1"
coalesce("", 15, "str3", ...) // return the string "str3"
coalesce("", "", "") // return undefined
----

* replace(s, old, new, count) 
** returns a copy of the given string, starting with the first 'count' non-overlapping instances of the old string replaced with the new one
** s: the input string
** old: the string to be replaced
** new: the string that replaces the old one
** count: up to the number of times the old string will be replaced.
** if count is less than zero, no limit on the number of replacement
----
let s = "a a a"
replace(s, "a", "Hello", 1) // return the string "Hello a a"
replace(s, "a", "Hello", 0) // return the string "a a a"
replace(s, "a", "Hello", -1) // return the string "Hello Hello Hello"
----

* match(pattern, s)
** return true if the input string s contains any match of the regular expression pattern.
** use the ^ and $ modifiers to denote if the regex pattern match the full input string.
----
let s = "Hello"
match("^H", s) // return true since s starts with "H"
match("^h", s) // return false since s does not start with "h"
----

* regexp(pattern, s)
** this function extracts the captured "named group" matching the regular expression pattern from s.
----
let Email = "foo@gmail.com"
let obj = regexp("(?P<Name>.*)@(?P<Domain>.*)", Email) // sets obj to {Name: "foo", "Domain: "@gmail.com}
let {Name, Domain} = regexp("(?P<Name>.*)@(?P<Domain>.*)", Email) // sets the var Name = "foo" and Domain = "@gmail.com"
let obj =regexp("(?P<Name>.*)@(?P<Domain>.*)", "foo") // return {}
----

* len(variable) 
** if variable is primitive string, returns the length of the input string
** if variable is primitive list, returns the length of the list
** if variable is primitive map, returns the number of key-value pairs in the map
** if variable is json array, returns the number of elements in the array
** if variable is json object, returns the number of key-value pairs in the object
** if variable is Tuple, returns the number of elements in the tuple
** if variable is Map, returns the number of key-value pairs in the map
** if variable is Table, returns row count of the table
** if variable is MetricStream, returns the number of data series in the metric
** if variable is Alert, returns the number of entries in the alert
** else return 0
----
len("Hello") // return an int64 value of 5
len([1, 2, 3]) // return an int64 value of 3
len({Name: "foo", Domain: "@gmail.com"}) // return an int64 value of 2
----

* append(list, element)
** if list is primitive string and element is primitive string, return a new string.
** if list is primitive list type and element is primitive value, appends element to the primitive value list
** if list is primitive json type and element is primitive value, appends element to the json array
** if list is tuple type, append element to the tuple
** else return error
----
let s = "ab"
s = append(s, "cd") // s is now the string "abcd"

let src = [1, 2, 3, 4]
append(src, 5) // src is now [1, 2, 3, 4, 5]
----

* delete(map, key)
** map must be primitive map, jsonObject or object map. 
** key must be primitive string
----
let m = {first: 10, second: 20}
delete(m, "first") // m is now the map {second: 20}
----

* typeof(variable)
** if variable is primitive value, returns the type of the primitive value: 
***       "string", "int64", "float64", "bool", "null", "undefined", "list", "map", "jsonObj", "jsonArray"
** else return the type of the object: 
***       "Tuple", "Map", "Lambda", "Table", "MetricStream", "Alert"
----
typeof(2) // return the string "int64"
typeof([1, 2, 3]) // return the string "list"
----

* isNull(var)
** return true if var is a null type, false otherwise
----
isNull("Hello") // return false
isNull(null) // return true
----

* isUndef(var)
** return true if var is undefined type, false otherwise
----
isUndef(null) // return false
----

* isString(var)
** return true if var is of string type, false otherwise
----
isString("abc") // return true
isString(64) // return false
----

* isNumber(var)
** return false if var is of int64 or float64 type, false otherwise
----
isNumber("abc") // return false
isNumber(64) // return true
----

* sprintf(format, arguments...)
** golang's printf format
** if format is not given, will default to string

* printf(format, arguments...)
** golang printf format
** if format is not given, will default to string
** format specifiers:
*** %v : formats the value in a default format
*** %d : formats decimal integers
*** %f : formats the floating-point numbers
*** %g : formats the floating-point numbers and removes trailing zeros
*** %b : formats base 2 numbers
*** %o : formats base 8 numbers
*** %t : formats true or false values
*** %s : formats string values
----
printf("%d", 2) // prints 2 as a string to traces
printf(2) // ERROR: expected string but int64 given
printf("2") // prints the string 2 to traces
----

* case(condition_1, value_1, [condition_2, value_2, ...], default_value)
** evaluate a list of conditions and returns the first value whose condition is evaluated to true. If all conditions are false, the default value is returned
----
let i = 10
case(i>10, "bigger than ten", i>=0, "positive", "negative") // return "positive"
let i = -10
case(i>10, "bigger than ten", i>=0, "positive", "negative") // return "negative"
----

== System Functions

* AWS_AccountRegionLambda(accounts, regions, (account, region) => { return {}  })
** Run lambda function on specific AWS accounts and regions
** accounts: "*" enable all configured AWS accounts. account could also be one account name or one array of names
** accounts: "Production" or ["Production", "UnitTest"]
** regions: "*" enable all configured regions
** regions: "us-east-1" or ["us-east-1", "us-east-2"]
** this function returns a map of objects
** results from different regions will be merged into one 

* AWS_AccountLambda(accounts, regions, (account) => { return {}  })
** lambda function on specific AWS accounts (One example is AWS Cost and Usage API, which does not limit to one specific region)

* transform(stream, lambda) 
** create a new stream. The data series of the new stream is the result of the lambda function.
** lambda function interface: (ts, key, value) => {  }
----
let duration = AWS_GetMetric("Duration", options, filters)
let invocation = AWS_GetMetric("Invocations", options, filters)
let durationCost = transform(duration, (ts, key, value) => (value/1000) * assetTable[key].lambdaMemoryRate)
let invocationCost = transform(invocation, (ts, key, value) => value * assetTable[key].lambdaRequestRate)
----

* anomaly(stream, {seasonal:"auto", minDiff: 3.0, minDiffPercent: 10.0})
** anomaly detection on one stream
** seasonal: auto | weekday-end-hourly | hourly | weekday-hourly | ""
** minDiff: absolute difference over mean: abs(value - mean)
** minDiffPercent: relative percent over mean: (value - mean)/mean
** return FplAlert object 

* RxFPL_GetMetric(metricName, {options} ) 
** Load metric from rxfpl database
** from: range from  
** to:   range to
** order: desc | asc  // default is desc
** limit: number of metrics // default is 10
** filters: search filters 
[source,javascript]
----
function main() {
  let cost = RxFPL_GetMetric("PureCloudOps.AWS.Billing.InstanceCost", {from:"-2h@h", to:"@h", filters:[{name:"lvdb-app", values:"archiveSearchV3", exclude: true}]})
  return {cost}
}
----

* alert(<stream>, window(condition,n,m))
** sliding window detection
----
function queueAlerts(queues) {
  let options = {from: "-1h@h", to: "@h", dimensions: ["QueueName"], namespace: "AWS/SQS", period: "5m", stat: "Maximum", unit:"Second"}
  let filters = {QueueName: queues}
  let ages = AWS_GetMetric("ApproximateAgeOfOldestMessage", options, filters)
  let ageAlerts = alert(ages, window(ages > 3600, 2, 2))
  options.stat = "Sum"
  let received = AWS_GetMetric("NumberOfMessagesReceived", options, filters)
  options.stat = "Average"
  let queueLength = AWS_GetMetric("ApproximateNumberOfMessagesVisible", options, filters)
  let consumerStopAlerts = alert(queueLength, window(received == 0 && queueLength > 1, 2, 2))
  return {ageAlerts, consumerStopAlerts}
}
----

== Object Methods

=== Table Methods

* IsEmpty() 
** return true if table is empty, false otherwise
----
testTable.IsEmpty()
----

* RemoveColumn(columnName)
** remove columnName from the table
----
testTable.RemoveColumn(col1) // removes col1 from testTable
testTable.RemoveColumn(col2) // removes col2 from testTable
----

* GetColumnValues(columnName)
** return a list of values on columnName from the table
----
testTable.GetColumnValues(col1) // returns [val1, val2, ...]
----

* GetKeys()
** return list of values from the key column: "ID" before the merge, "_globalID" after the merge.
----
testTable.GetKeys() // return [k1val1, k1val2, k2val1, k2val2, ...]
----

* SetColumnUnit(column, unit)
** set the unit of column
----
testTable.SetColumnUnit("Cost", "USD" // sets the Cost column to USD)
----

* Sort(limit, "+col1", "-col2"...)
** sort the table by column values and limit to the first N. 
** limit = 0 will return all results.
** "+" for ascending and "-" for descending, if not specified then defaults to descending order
----
// return top 10 rows, sort by "Cost" column in descending order
natGateways.Sort(10, "Cost")
----

* Join(sourceTable, {keyColumn1, keyColumn2...}, {OtherColumns...})
** join sourceTable on keyColumn(s). if the third parameter is not provided, all columns from the sourceTable will be merged.
** {ID:"ID"} => Both left column and right column is named "ID"
** {ID:"VpcId"} => right column is "ID", left column is "VpcId"
----
bucketTable.Join(byteSummary, {ID:"ID"}, {Total_Bytes:"Total_Bytes", Total_Cost:"Total_Cost"})
// if keycolumn(s) is not provided, the default key column will be "ID"
bucketTable.Join(byteSummary)
----

* GroupBy(({col1, col2 ... }) => [ {col1}, {sum:{Total: col2}} ])
** the input is a lambda function. 
** the input object destructuring pick up the columns in the table 
** the return is one array. the first object specify the groupBy fields
** the second object specify the aggregatioin columns.
** sum is the aggregation function 
** Total is the column name.
** sum:{Total: col2} define a new column "Total" which is the sum of the column "col2".  this is equivalent to "sum(col2) as Total" in SQL
** sum:{col2} is equivalent to sum:{col2:col2}
** for "count" aggregate, a bool expression is expected.
** count: {Count:true}
** available aggregate functions: count, sum, avg, min, max, values, coalesce, first
----
   let customerTable = bucketTable.GroupBy(({Customer, S3_Cost}) =>  {
      return [{Customer}, { sum:{S3_Cost} }]
   })
----

* Aggregate(columnName, unit, (ID, columnName, value, sum) => { }, 0)
** return a new table the same ID column, plus one new column which is the aggregated result from the calling table.
----
// simple sum of all columns from the table named "bucketTable"
// new table "byteSummary" has the same ID column plus one "Total_Bytes" column
let byteSummary = bucketTable.Aggregate("Total_Bytes", "Byte", (ID, col, value, sum) => {
      return sum + value
},0)

// more complicate example, the lambda calls AWSPrice API to get the monthly cost of different S3 storage types.
// the table "bucketTable" is derived from the "DimensionTable" method of a metric stream, each storage type has one column
let costSummary = bucketTable.Aggregate("Total_Monthly_Cost", "Dollar", (ID, col, value, sum) => {
      return sum + AWSPrice("S3", "StorageType", {Size:value, Type:col})
}, 0)
----

* NewColumnLambda(columnName, unit, (row) => {   })
** Generate one new column on the calling table. The column value is the return value of the lambda function.
----
// create a new column "AverageSize"  on table "bucketTable".  The new column will read the two column named "Total_Bytes" and "Total_Object_count" respectively and calculate the the average as column value.  
bucketTable.NewColumnLambda("AverageSize", "Byte", (row) => row.Total_Bytes / row.Total_Object_Count)
// OR 
bucketTable.NewColumnLambda("AverageSize", "Byte", ({Total_Bytes, Total_Object_Count}) => Total_Bytes / Total_Object_Count)
----

* JoinStream(stream, aggregationType, columnName, unit)
** Generate one new column on the calling table. The column value is the aggregated result of each data series.
[source,javascript]
----
function getNatBandwidth(assetTable) {
  let options = {from: "-24h@h", to: "@h", dimensions: "NatGatewayId", namespace: "AWS/NATGateway", period: "1h", unit:"Byte", stat: "Sum"}
  let filters = {NatGatewayId: assetTable}
  let download = AWS_GetMetric("BytesInFromDestination", options, filters)
  let upload = AWS_GetMetric("BytesOutToDestination", options, filters)
  let localUpload = AWS_GetMetric("BytesInFromSource", options, filters)
  let localDownload = AWS_GetMetric("BytesOutToSource", options, filters)
  let totalBytes = download + upload + localUpload + localDownload
  let processCost = AWS_GetPrice("NatGateway", "GB")
  let hourlyCost =  AWS_GetPrice("NatGateway", "Hour")
  let cost = (hourlyCost * 3600 / totalBytes.GetInterval()) +  totalBytes * processCost / (1024 * 1024 * 1024)
  return {download, upload, totalBytes, cost}
}

function main() {
  return AWS_AccountRegionLambda("*", "*", (account, region) => {
    let natGateways = AWS_LoadAsset("ec2:natgateway", (obj) => {
       let {NatGatewayId:ID, State, VpcId} = obj
       let PublicIp = obj.NatGatewayAddresses[0].PublicIp
       return {ID, State, VpcId, PublicIp}
    })

    let {totalBytes} = getNatBandwidth(natGateways)
    natGateways.JoinStream(totalBytes,"Sum", "TotalBytes", "Byte")
    return {natGateways}
  })
}
----

== Metric Stream Methods

* IsEmpty()
** return true is the stream has no data series
----
cpu.IsEmpty()
----

* Sort(limit, "AggregationType1", "AggregationType2"...)
** sort the stream by aggregation(s)
----
// top 10 CPU utilizations
cpu.Sort(10, "Average")
----

* SummaryTable(column, unit, aggregationType)
** create a new table with a new column which holds the aggreation results for each data series
** aggregationType:  Sum|Average|Min|Max|Count|Last
----
// create a new table "invocationSummary" with a column "Total_Invocations"
let invocationSummary = lambdaInvocations.SummaryTable("Total_Invocations", "Count", "Sum")
----

* TimeTable(timeFormat, unit)
** create a new table. each column is a time slot rendered with the format.
** the time format Golang Time Format
----
let timeTable = balance.TimeTable("Jan 02 15:04:05", "Percent")
----

* DimensionTable(dimension, unit, aggregationType)
** for metric stream with two dimensions. choose one dimension as the key dimension. the value of the other dimension will become a new column in the created new table
----
function getS3BucketSize(assetTable) {
 let options = {from:"-48h@d", to:"@d", dimensions=["BucketName","StorageType"], namespace:"AWS/S3", period:"24h", stat:"Average"}
 let filters = {BucketName:assetTable}
 let size = AWS_GetMetric("BucketSizeBytes", options, filters)
 let objCount = AWS_GetMetric("NumberOfObjects", options, filters)
 return {size, objCount}
}

function main() {
  return AWS_AccountRegionLambda("*", "*", (account, region) => {
    let buckets = AWS_LoadAsset("s3:bucket", (obj) => { return {ID: obj.Name} })
    let {size, objCount} = getS3BucketSize(buckets)
    let bucketTable = size.DimensionTable("StorageType","Byte","Last")
    let countTable = objCount.DimensionTable("StorageType","Count","Last") 
    return {bucketTable, countTable}
  })
}
----

* SetTags(assetTable) 
** convert asset table columns into tags for the metric stream key
* SetUnit(unit)
** set unit for metric stream

=== FplAlert Methods

* Limit(n)
** keep the topN anomalies

* Emit(name, description, severity, OffDelay)
** severity: error | warn | info
** OffDelay: alert will be cleared after OffDelay seconds. -1 means never expires

== Bulit-in Resource Loading Support

* AWS_Cli_List(<cmd_line>, (obj) => { }) 
** list AWS assets via AWS cli

* AWS_Cli_Get(<cmd_line>, idList, (id, obj) => {})
** get asset attributes from a list of ID

* NOTE the AWS_Cli_List and AWS_Cli_Get are not open for production deployment. For security concerns.  If the role IAM policy is not properly configured, it may cause security issues.
----
let natGateways = AWS_Cli_List("ec2 describe-nat-gateways", (obj) => {
      let ID = obj.NatGatewayId
      let State = obj.State
      let VpcId = obj.VpcId
      let PublicIp = obj.NatGatewayAddresses[0].PublicIp
      return {ID, State, VpcId, PublicIp}
})
// call AWS cli:  "aws ec2 describe-nat-gateways"
// same as AWS_LoadAsset( "ec2:natgateway", ...
function main() {
   return AWS_AccountRegionLambda("*", "us-west-2", () => {
      let queues = AWS_Cli_List("sqs list-queues", (url) => {
         let QueueUrl = url
         let segments = split(QueueUrl, "/")
         let ID = segments[len(segments)-1]
         let fifo = endsWith(ID, ".fifo")
         return { ID, QueueUrl, fifo }
      })

      let queueTags = AWS_Cli_Get("sqs list-queue-tags --queue-url", queues.GetColumnValues("QueueUrl"), (id, obj) => {
           let QueueUrl = id
           let TagCount = len(obj.Tags)
           return {QueueUrl, TagCount}
      })

      let queueAttributes = AWS_Cli_Get("sqs get-queue-attributes --attribute-names All  --queue-url", queues.GetColumnValues("QueueUrl"), (id, obj) => {
           let QueueUrl = id
           let QueueArn = obj.Attributes.QueueArn
           return {QueueUrl, QueueArn}
      })
      queues.Join(queueTags, {QueueUrl:"QueueUrl"})
      queues.Join(queueAttributes, {QueueUrl:"QueueUrl"})
      return {queues}
   })
}
----

* AWS_LoadAsset(<resource>, (obj) => { })  // load AWS resources and convert them into a table
** lambda:function
** ec2:vpc
** ec2:instance
** ec2:volume
** s3:bucket
** ec2:natgateway
** eks:cluster
** eks:nodegroup
** sqs:queue
** elasticloadbalancing:loadbalancer
** elasticloadbalancing:targetgroup
** apigateway:apis
** if the lambda function return null, the entry will be skipped (filterMap function)
** jsonGetTag(obj, <tagArrayPath>,  <keyField>, <keyValue>, <valueField>)
----
   "Tags": [
       {
        "Key": "Name",
        "Value": "my-instance"
       }
   ],
   // let Name = jsonGetTag(obj, "Tags", "Key", "Name", "Value")
   // OR let Name = jsonGetAWSTag(obj, "Name") 
----
** jsonGetAWSTag(obj, <tagName>) // same as jsonGetTag(obj, "Tags", "Key", <tagName>, "Value")

* LoadAsset with GroupBy
** the return is one array. [ "groupBy", {groupByKey1,...}, { aggregates }
** the groupBy fields and aggregates use the same format as table.GroupBy()
----
return AWS_AccountRegionLambda("*","*", () => {
      let volumes = AWS_LoadAsset("ec2:volume",({VolumeType, State, Iops, Size}) => ["groupBy", {VolumeType}, {Sum:{Size}}])             
      volumes.SetColumnUnit("Size", "GB")
      return {volumes}
})
----

== Built-in Metric Loading Support

* AWS_GetMetric(metricName, options, filters)  // load AWS metrics
** options: {from, to, dimensions, namespace, period, stat, unit, timezone}
** options.dimensions could be one string or a list of strings
** filters: {dimensionName: assetTable}
----
function getLambdaCost(assetTable) {
  let options = {from: "-60m@m", to: "@m", dimensions: "FunctionName", namespace: "AWS/Lambda", period: "5m", stat: "Sum"}
  let filters = {FunctionName:assetTable}
  options.unit = "Millisecond"
  let duration = AWS_GetMetric("Duration", options, filters)
  options.unit = "Count"
  let invocation = AWS_GetMetric("Invocations", options, filters)
  return {duration, invocation}
}
----

== Built-in AWS Pricing API

* AWS_GetPrice(service, resource, options)
** service: "Lambda", resource: "GB-Second" , "Request"
** service: "S3",  resource: "StorageType"
** service: "NatGateway", resource "GB" , "Hour"
** service: "ApplicationLoadBalancer", resource "Hour", "LCU-Hour"

* AWS_GetCostUsage(options)
** from: report start time
** to:  report end time
** metric: AmortizedCost | BlendedCost | UnblendedCost | UsageQuantity
** granularity:  DAILY |  HOURLY
** dimensions:  AZ, INSTANCE_TYPE, LEGAL_ENTITY_NAME, INVOICING_ENTITY, LINKED_ACCOUNT, OPERATION, PLATFORM, PURCHASE_TYPE, SERVICE, TENANCY, RECORD_TYPE, and USAGE_TYPE
** tags:  customer defined cost allocation tags
----
function main() {
 return AWS_AccountLambda("Production", () => {
    let dailyUsage=AWS_GetCostUsage({from:"-60d@d", to:"-1d@d", metric:"UsageQuantity", granularity:"DAILY"})
    let dailyBlended=AWS_GetCostUsage({from:"-30d@d", to:"-1d@d", metric:"BlendedCost", granularity:"DAILY"})
    let dailyUnBlended=AWS_GetCostUsage({from:"-30d@d", to:"-1d@d", metric:"UnblendedCost", granularity:"DAILY"})
    let dailyAmortized=AWS_GetCostUsage({from:"-60d@d", to:"-1d@d", metric:"AmortizedCost", granularity:"DAILY"})
    let dailyCostByService=AWS_GetCostUsage({from:"-30d@d", to:"-1d@d", metric:"AmortizedCost", granularity:"DAILY", dimensions:"SERVICE"})
    dailyCostByService.Sort(10)
    return {dailyUsage, dailyBlended, dailyUnBlended, dailyAmortized, dailyCostByService}
 })
} 
----

== Comparison with SQL and Splunk Processing Language

* Language design
** SQL/SPL  are all "script". No if/else. Difficult to learn for programers.
** FPLv2: javascript es6 grammar. Real programming language with if/else statement,for loop and exception support.
* Data Source
** SQL: relational database
** SPL: data lake
** FPLv2:  data lake, any document based database, key-value store, time series database (TSDB). Support both json document store and metric data stream.
** FPLv2:  support data source based on cloud API, such as cloudwatch get_metric api, AWS management "describe*" and "list*" APIs.
* Throughput and Efficiency
** FPLv2: Native execution in Golang. Built-in support for pallel multi-account, multi-region data queries.
* Report/Alert 
** FPLv2: Fully automated anomaly detection. Support table/chart/alert rendering.
* Data streaming support
** SQL/SPL: n/a
** FPLv2:  support streaming mode, parse/normalize streaming data

== Code comparison:

* SELECT
----
// SQL
SELECT col1, col2 from table1 where col3="hello"

// FPLv2
Load("remoteAsset", ({col1, col2, col3}) => { 
                       if col3=="hello" {
                          return {col1, col2}
                       }
                       return null
                    }) 
   
----
* GROUPBY
----
// SQL
SELECT col1, sum(col2) from table 
WHERE col3="hello"
GROUP BY col4

// FPLv2
Load("remoteAsset", ({col1, col2, col3, col4}) => { 
                       if col3=="hello" {
                          return [ "groupBy", {col4}, {sum:{col2}} ]
                       }
                       return null
                    }) 

----
* JOIN
----
// SQL
SELECT * from table1
INNER JOIN tabl2
ON table1.col1=table2.col2

// FPLv2
table1.Join(table2, {col2:"col1"})
----

* Sort
----
// SQL
SELECT * from table1
ORDER BY col1 desc
// FPLv2
table1.Sort(0, "-col1")
----
